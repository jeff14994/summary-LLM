import os
from dotenv import load_dotenv
from loguru import logger
from summarizer.local_llm import LocalLLM

# Configure logger
logger.remove()
logger.add("test_local_llm.log", level="DEBUG")

def test_local_llm():
    # Load environment variables
    load_dotenv()
    
    # Initialize LocalLLM
    llm = LocalLLM()
    
    # Test input
    test_input = """
你是一個專業的會議記錄摘要生成助手。你的任務是根據提供的會議記錄內容，生成結構化的摘要。
請遵循以下格式生成摘要：
1. 摘要要點：列出3-5個最重要的討論點
2. 結論：簡要總結會議的主要結論
3. 行動項目：列出需要跟進的具體行動項目

請確保摘要：
- 保持客觀中立
- 突出關鍵決策和行動項目
- 使用清晰簡潔的語言
- 保持原始內容的準確性

請根據以下會議記錄生成摘要：

採訪者: 我們先談一下，就是當初其實你第一次使用到 DeepSeek 的時候，那個經驗是怎樣的？因為它上個禮拜出來的時候，大家就是感覺很驚豔的樣子嘛。

唐鳳: 嗯，你指的是 DeepSeek R1，是不是？就是最新的這個模型？

採訪者: 是，最新的這個版本。

唐鳳: 我是應該是 13 天前注意到的，就兩個星期前。當時它並沒有什麼媒體的報導，就是上傳到了 Hugging Face 上面。

唐鳳: 因為我本來就有這個習慣，會把 Hugging Face 上面新的這些模型下載下來。那所以就是下載下來，然後就很自然地就自己來使用這樣。

採訪者: 那當初你第一次使用到那個 R1 的時候，你自己的使用經驗是如何？就是會覺得說它真的很……就是有點超越了現在那個 OpenAI 的那個模型？

唐鳳: 因為我自己是 O1 Pro 的使用者，所以 O1 Pro 我日常相當常使用。當然，跟 O1 Pro 相比的話，R1 並沒有比較精確，也沒有比較有創造力，在各方面來講，都並沒有到 O1 Pro 的那個程度。

採訪者: 是。所以就是看到上個禮拜，很多媒體都將 R1 跟 O1 Pro 去做一個比較的時候，你自己看到的感覺是怎麼樣的？

唐鳳: 因為 O1 Pro 它是 O1 用比較多的算力的版本。那大部分的使用者，用的 O1 可能是算力比較小的版本，不管是 O1 Mini 或者是 O1。所以跟那些相比的話，特別是在華文的處理上面，當然會覺得說 DeepSeek 比較流暢，比起 O1 來講，那當然也是因為它訓練裡面比較多華文的語料。

唐鳳: 那當你用到 O1 Pro 的時候，它對於華文，以及各個地方不同的華文各自的特性，它的掌握就還是更深一點。

採訪者: 瞭解。那當初其實就是，因為看到你在回覆的時候，會跟大家講那個破解的方法。其實當時就是想到那個破解方法的時候，是因為知道可能離線的版本比較沒有那麼多審查？還是就是如何去進行這個破解審查的步驟？

唐鳳: 先要講的是，當時我並沒有去使用網頁上或者 APP 上面的版本，我並沒有管這件事情，因為我通常都是直接關注 Hugging Face 上面的模型。

唐鳳: 那當然我也觀測到說，它裡面可能有兩層結構：一層是碰到政治議題或者敏感話題的時候，它就想都不想，就會講出官方的敘事來。

唐鳳: 所以你可以觀察到，在普通的題目上面，它都會先有一個思考的過程，思考完之後再進行回答；但是如果是碰到特定的關鍵詞，它思考的過程會跳過，那就直接回答一個官方敘事的版本。這個是不常見的，就是顯然是它特別有設計這一段進去。

唐鳳: 另外一個，也是大家也在講的，就是說它因為訓練的資料集，可能對於不管政治啊、社會科學類的問題等等，它的那些資料集的來源可能有特定的意識形態。所以它會想、也會回答，但是那個回答裡面帶著那些意識形態，那當然也是有這個部分。不過我首先注意到的是前面的那個部分。

採訪者: 是。那所以當時其實注意到那個部分的時候，就是知道其實可能離線版本，它會比較沒有線上或者是它 APP 的版本那麼多嚴重的審查。

採訪者: 還有因為剛才有提到說，那個思考的過程它會展現出來。可是我在 research 的時候，我看到有不少的用戶，他們嘗試輸入一些敏感的詞去查的時候，線上的版本可能有嘗試去輸入一些答案出來，可是可能兩秒之後就已經刪除了，就是那個沒有辦法？

唐鳳: 對，這是額外的，就是說這裡總共有三層系統：

唐鳳: 第一層是線上或 app 才有的，它即使開始回答，也會被蓋過。

唐鳳: 第二個是我剛才講的，就是說即使是在離線的版本裡頭，它也是有對於關鍵詞跟歷史事件，會跳過思考去做出不自然的這種迴避。那這個當然也會引發大家不信任，或者不想使用，覺得審查痕跡太深。

唐鳳: 第三個才是它自然的回答，但是回答裡面透露出特定的意識形態。

採訪者: 是。所以那個它透露出的那個意識形態，也是因為透過它本身的那個模型的訓練去把它……怎麼講，就是餵出來的一個情況出現嗎？

唐鳳: 對。但是我們目前也已經看到，像Perplexity.ai 它所內嵌的那個 R1 的版本，就是他們已經透過模型的權重的修改，把裡面自我審查、不自然的迴避等等這些部分都去除了。所以你即使是在 Perplexity 不開搜尋，你用所謂的輔助寫作模式，去問 Perplexity 版本的 R1 這些問題，包含剛才講到的關鍵詞、歷史事件，它都會很正常地回答。

唐鳳: 這就表示說，事實上是因為它的權重釋出，可以修改到可以把這些不自然的迴避去除掉。

採訪者: 瞭解。

採訪者: 剛才我們有談到，可能就是你不同的指令或者是那個關鍵詞，為什麼會出現這麼不一樣的結果？比方說你用那個「天安門事件」跟「天安門屠殺」，就會出來非常不一樣的回答內容。

唐鳳: 我還沒試過「天安門屠殺」，我是試「天安門慘案」。

唐鳳: 因為它的本質是一個文字接龍嘛，所以不同的措辭，它後面通常就會接不同的描述，也就是那個措辭本身是有一個定性的。

唐鳳: 我想我們在寫作的時候也會看到，像一篇報導的標題，它標題使用什麼，那你大概也可以猜出它裡面的內文要用什麼樣的筆調來描寫。

唐鳳: 因為語言模型它基本上是接龍的能力，所以你在告訴它標題之後，它後面的那個回答的內容，也就會跟著這樣子來接續。

採訪者: 是。可是當時其實有想過，比方說線上的版本，它會出現這麼多審查的情況，因為我看有一些的報導裡面講說，問「習近平是誰」他其實也不願意回答，好像很多的話題他都不願意去回答的狀況？

唐鳳: 所以我剛才有強調，就是說我們臺灣當然是非常強調言論自由，強調多元參與。如果碰到技術或者產品有這樣子的情況的時候，一方面當然比較不信任、不想使用，二方面就是會運用我剛才所說的其他那些技術。

唐鳳: 好比說我舉例，除了 Perplexity 之外，Hugging Face，也就是我一開始發現有這個模型的地方，他們自己也開始了所謂的 Open-R1，也就是說運用 R1 的這種訓練的方式，但是不加入審查模組。

唐鳳: 所以不是說把 R1 下載下來之後，把審查模組去削除掉，而是沿著 R1 的方式重新訓練一次，從一開始就不加入這些審查模組。那這個情況下，當然將訓練出來的 Open-R1，相信在這方面就不會有這種讓人覺得「怎麼忽然之間就很不自然」的回應情況。

唐鳳: 所以也可以期望說，像 Open-R1 這樣子比較透明的模型，也可以更多地被運用在其他的大廠裡面，就不一定要自己再用 DeepSeek-R1 然後再去進行修改等等。那這是一部分。

唐鳳: 那另外一部分是說，我們也已經看到 Hugging Face 上面，開始有各國都自己拿了 R1，然後再加入自己的語言材料。那這樣子就比較容易來處理剛剛講第三層的這個問題，就是因為它比較片面地吸收一些資訊，所以導致它即使願意回答，還是有特定的意識形態。

唐鳳: 舉例來說，像日本的 CyberAgent，就運用日文的語料去做了額外的訓練，所以當你問這些敏感的問題，但是用日文問的時候，他就不會受到本來的意識形態限制。

採訪者: 所以好像說，用英文在問的時候，線上的那個版本回答也會比較不一樣？

唐鳳: 對，相對上。但剛剛講的就是說，因為它的權重是開放的，所以當你下載下來，然後再繼續用好比像剛才講的日文語料來訓練的時候，它碰到日文的問題，就會傾向你後面給它加強的那個版本。

唐鳳: 所以目前看起來就是兩個：一個是比較徹底的，就是自己重新按照 R1 的做法訓練一次；第二個是拿著 R1 把它第二層的審查模組移除，或者是再加上新的語料，去讓它在第三層的意識形態做修正，那這樣是處理掉第二層跟第三層的問題。那第一層因為本來你下載下來，就不需要靠著它的網頁界面或者 app，所以這樣子的話，第一層本來就不存在問題。

採訪者: 是。可是我在想說，如果技術沒有那麼強的使用者，可能他們只會使用那個 APP 或者是網頁的版本。那對於他們來講，其實這種言論審查會如何影響他們會選擇哪一種 AI 產品？或者是這種類型的產品，對於比較 layman 的人來說，他們那個潛在的問題會是什麼呢？

唐鳳: 我不確定您的意思是什麼？好比像說現在你如果到 chatgpt.com，那當然它不會提供 R1，它現在提供的是 O3 Mini。那你可以按個「思考」按鈕，就可以使用 O3 Mini。那 O3 Mini 在各方面都跟 R1 相比，很多方面更好一些。

唐鳳: 所以您剛剛講的是說，好，那我現在有免費的 O3 Mini 可以用，我有免費的 DeepSeek R1 可以用，在兩邊都可以用的情況下，大家做選擇的考量是什麼？是這樣的問題嗎？

採訪者: 對對，類似。就是如果那個 APP 或者網頁的版本的 DeepSeek，它就很明顯有這種——如果你要問他一些正式的東西或者是社會的事情，他就會這樣去回答，而不是純粹的一些 code 或其他數據的推理。對於 user 來講，他們那個選擇會不會就不太會去選擇 DeepSeek 的使用呢？

唐鳳: 應該這樣講，就是說，如果同樣是免費的使用，那 DeepSeek 的品質又沒有特別更好，它又有這方面意識形態方面偏見的狀況，那當然對使用者來說，這並不是一個取捨。

唐鳳: 也就是說，我既可以用功能同等或者更好，而且又比較沒有這種意識形態的問題，那大部分使用者應該還是會去使用比較沒有這方面問題的。

唐鳳: 你剛剛的問題只有在要做出權衡時：就是 DeepSeek R1 真的比其他的產品都好得多，而且讓大家覺得好像非得忍受一下它的意識形態審查機制——那樣才會造成問題，但是現在並沒有。

唐鳳: 除了 OpenAI 之外，像 Gemini 它也有 AI Studio，裡面也有它所謂的 Flash Thinking，事實上現在在很多排名裡面是最好的，所以同樣地，它也沒有這種意識形態的問題。那也有很多人，如果完全不願意付錢的話，也可以直接去使用 Gemini 的 Flash Thinking。

採訪者: 瞭解。關於這個問題，也是因為比方說不是華文的地區，就在上個禮拜——不是說它在應用程式的一些商店，就上到了第二名的下載排行榜嗎？所以如果他是透過應用程式商店去下載 APP 版本。

採訪者: 我在想，對於那些會下載 APP 的人來講，DeepSeek 對他們的吸引力到底是什麼呢？如果他會有這麼多審查問題存在？

唐鳳: 一方面是說，因為各地的新聞都在討論嘛，那下載 APP 並不是需要花很多時間，所以很多人會看到新聞就覺得「那我也來用一下看看」。

唐鳳: 當然在臺灣這邊，我們也看到像數位發展部已經很快就說，你如果使用它的 APP 或者用它的網頁服務，那資料基本上它的儲存以及之後怎麼運用等等，基本上就是 DeepSeek 那家公司說了算。

唐鳳: 所以數位發展部馬上就提出說，在公部門也好，公立學校也好，它是所謂的危害產品，就是說跟 TikTok 一樣，是中共可以實質控制的，所以不能來使用。它特別講的就是 DeepSeek 的這個服務，包含 web 跟 app 的部分。

採訪者: 有這方面的風險嗎？所以它的情況也會跟其他中國的那種 APP 很類似嗎？比方說小紅書啊那些？

唐鳳: 對，我們在 2019 年開始，就有《危害國家資通安全產品限制使用原則》。這個原則著重的就是，不管它標明產地是哪個國家，只要是受境外敵對勢力的實質控制，那公務機關無論是他們自行營運，或者委外營運、提供公眾活動使用的場地等等，都是限制的。主要原因當然就是它的實質控制權，這個遙控權並不在我們可掌握的範圍之中。

唐鳳: 那當然，如果是像剛剛講到的 Hugging Face，自己按照 R1 那篇論文重新訓練出 Open-R1，就沒有這個問題。雖然它用的原理是一樣的，但是實質的控制權並不是在北京當局手上。

採訪者: 瞭解。所以現在各地方開始提出的那些安全風險的擔憂，主要就是跟你剛才談的比較類似？

唐鳳: 對，就是他的擔憂第一層是，這個 APP 或者這個網頁會在沒有辦法有效監管的情況下外流，並且構成危害的風險，這是第一層。

唐鳳: 我們剛剛另外講的包含第二層、第三層，就是這個模型的權重裡面內建一些審查的本能，以及它的訓練資料裡面帶有特定的意識形態。那這是不同層。所以剛剛講的「危害產品」，是在講第一層。

採訪者: 那它的意識形態會導致的那個安全風險，會不會是在使用者使用的時候，影響到它回答的那個方向？

唐鳳: 這是一個嘛。那另外一個就是，如果你去看 R1 的論文的話，它特別有對於怎麼樣幫助使用者、怎麼樣減少對使用者的危害，做一些訓練，但是在「誠實」上面，論文裡面比較沒有提到。

唐鳳: 那這樣的結果就是說，你要求 DeepSeek-R1 模型生成一些比較惡意的用途，好比像去進行人身攻擊，或者是去進行一些訊息散佈、詐騙劇本等等，它基本上是不會拒絕的。

唐鳳: 所以這也是另外一個方面，就是它在訓練過程裡面儘可能去迎合使用者的需要，但如果使用者是具有惡意的使用者，它比較沒有做這方面的防制。

採訪者: 瞭解。那其實它現在所面對的一些審查情況，會不會影響到它作為一個讓 R1 模型讓大家比較驚豔的情況？還是說其實只要你下載下來，再進行自己的一個訓練，其實也不太會影響？

唐鳳: 應該是，剛剛講說如果像 Perplexity，那樣子看起來是蠻徹底地去突破第二層。如果你是用它來進行網頁檢索搜尋，它會有 grounding，就是它會用找出來的那些網頁結果當作事實，所以它在第三層的這個自己「幻覺」出特定意識形態的問題，也比較不大，因為它會用實際網頁找出來的那些結果來做 grounding。

唐鳳: 所以用 Perplexity 的版本，我目前到現在的感覺，不能說完全解決第二層、第三層的問題，但是已經有效去防堵到一個程度。但當然要徹底解決這個問題，還是像剛剛講到的 Open-R1 這樣子，重新訓練一個。

唐鳳: 那當然也有一個很簡單的，就是大家也可以去用 Gemini Thinking，那個也是免費的，或者是 O3 Mini 等等，用其他 AI 公司的模型。因為在大家所看中的那些層面，包含寫程式、推理等等上面，Gemini Thinking 或者 O3 Mini 並沒有比較差，所以其實這不是一個需要做出的權衡。

採訪者: 是，瞭解。那對你來說，這個 R1 的發展，你自己使用了這麼久，你的感覺是如何呢？

唐鳳: 倒沒有，我就像我剛剛講的，我到現在還是主要用的是 O1 Pro。

唐鳳: 所以我只是說，它剛出來的時候，就剛出來一兩天吧，我因為定期會看 Hugging Face 上面新的模型，所以有下載下來在本機來試用。那 Perplexity R1 剛出的時候，我因為想知道它有移除掉多少這種審查，所以也用了一陣子。但是我現在日常最常用的，還是 O1 Pro，然後配一些 O3 Mini High。

採訪者: 瞭解。那最後一個問題想問一下，現在大家到這個禮拜也還在討論 DeepSeek 的事情。你自己如何……雖然它的討論現在也只有一個禮拜而已，可是你有沒有一些想法？你如何看待 DeepSeek 之後的發展呢？

唐鳳: 我覺得比較重要的還是說，因為這個禮拜，大家對於自己的資料權利、隱私權利、言論自由等等，越來越重視了，可以看到討論都是繞著這個在轉。

唐鳳: 我覺得這是很好的事情，因為大家越注重這些基本的人權——人權不只是存在於類比世界，線上世界也是一樣的。所以這個部分，我覺得越討論，大家就越會有一個共識，就是你至少需要尊重到哪些權利才是好的。

唐鳳: 那這也對於接下來 open source（開源）的發展，是一件正面的事情。因為在國際上面也有討論說，open source 到底能不能促進我們剛剛講到的那些權利，還是因為很容易產生詐騙、深偽等等，會削弱這些權利？這是一個很大的討論。

唐鳳: 但如果現在大家的討論是往「open source 怎麼樣才能盡到社會責任，甚至是能夠透過開源的方式，一起設計某些能夠抵禦惡意用途的共通工具」等等，那這樣大家就會把 open source 接下來的發展，引導到對社會、對人權都比較好的一個方向。

採訪者: 好，那我今天想問的問題就差不多。非常感謝，你這麼晚都還在接受我的訪問。

唐鳳: 沒問題，感謝。我後面這一段我會做逐字稿，但是我會等您發佈之後再發布。

採訪者: 好，沒問題。那之後如果這篇文章這個禮拜出來了，我就再把連結發給你。

唐鳳: 好的，謝謝。
"""

    # Generate summary
    try:
        logger.info("Starting summary generation...")
        summary = llm.generate_summary(test_input)
        logger.info("Summary generated successfully")
        logger.info(f"Summary: {summary}")
    except Exception as e:
        logger.error(f"Error generating summary: {str(e)}")
        raise

if __name__ == "__main__":
    test_local_llm() 